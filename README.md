# ğŸ›¡ï¸ Proyecto BI â€“ Inteligencia de Negocios

Este proyecto integra **tres fuentes de datos distintas**, cada una cargada en **PostgreSQL** y analizada con **Python (pandas, SQLAlchemy, Jupyter)**.  
El objetivo es construir **DataFrames principales** para exploraciÃ³n, aplicar filtros representativos y generar valor de negocio a partir de los datos.

---

## ğŸ“‚ 1. Counterfeit Product Detection Dataset

**Fuente:** Kaggle â€“ [Counterfeit Product Detection](https://www.kaggle.com/datasets/aimlveera/counterfeit-product-detection-dataset)  
**Tabla en PostgreSQL:** `counterfeit_transactions`

### DataFrames principales
- **Transacciones (`df_transacciones`)**  
  Variables: `transaction_id`, `transaction_date`, `customer_id`, `quantity`, `unit_price`, `total_amount`, `payment_method`, `shipping_speed`, `discount_applied`, `refund_requested`, `velocity_flag`, `geolocation_mismatch`.  
  - Filtros:
    1. Transacciones de alto valor (top 10%).  
    2. Transacciones con banderas de riesgo.  
    3. Transacciones con descuentos elevados.

- **Clientes (`df_clientes`)**  
  Variables agregadas: `total_pedidos`, `monto_total`, `ticket_promedio`, `tasa_reembolso`, `flags_riesgo`, `customer_location_mas_comun`.  
  - Filtros:
    1. Clientes VIP (top 10% por monto).  
    2. Clientes riesgosos (alto reembolso o banderas de fraude).  
    3. Clientes frecuentes (â‰¥ 5 pedidos).

- **LogÃ­stica (`df_logistica`)**  
  Variables: `shipping_speed`, `delivery_time_days`, `shipping_cost`, `sla_dias`, `cumple_sla`.  
  - Filtros:
    1. EnvÃ­os fuera de SLA.  
    2. EnvÃ­os costosos (top 10%).  
    3. EnvÃ­os lentos (â‰¥ 10 dÃ­as).

---

## ğŸ“‚ 2. Olist Customers Dataset

**Fuente:** Kaggle â€“ [Brazilian E-Commerce Public Dataset by Olist](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce)  
**Tabla en PostgreSQL:** `olist_customers`

### DataFrames principales
- **Clientes (`df_clientes`)**  
  Variables: `customer_id`, `customer_unique_id`, `customer_zip_code_prefix`.  
  - Filtros:
    1. Clientes Ãºnicos por `customer_unique_id`.  
    2. Clientes con ZIP > 90000.  
    3. Clientes duplicados en `customer_id`.

- **Ubicaciones (`df_ubicaciones`)**  
  Variables: `customer_city`, `customer_state`.  
  - Filtros:
    1. Clientes de SÃ£o Paulo (`SP`).  
    2. Clientes de las 10 ciudades mÃ¡s frecuentes.  
    3. Clientes fuera de SP y RJ.

- **Identificadores (`df_identificadores`)**  
  Variables: `customer_id`, `customer_unique_id`.  
  - Filtros:
    1. Conteo de IDs Ãºnicos.  
    2. Duplicados en `customer_unique_id`.  
    3. Top 10 IDs mÃ¡s repetidos.

---

## ğŸ“‚ 3. Customer_DF Dataset

**Fuente:** Dataset acadÃ©mico de fraude en clientes.  
**Tabla en PostgreSQL:** `customer_df`

### DataFrames principales
- **Contacto (`df_contacto`)**  
  Variables: `customerEmail`, `customerPhone`, `customerDevice`, `customerIPAddress`.  
  - Filtros:
    1. Emails con dominio `gmail.com`.  
    2. Dispositivos mÃ³viles.  
    3. IPs duplicadas.

- **Transacciones (`df_transacciones`)**  
  Variables: `No_Transactions`, `No_Orders`, `No_Payments`.  
  - Filtros:
    1. Clientes con > 5 transacciones.  
    2. Clientes con > 3 Ã³rdenes.  
    3. Clientes con 0 pagos.

- **Riesgo (`df_riesgo`)**  
  Variables: `customerBillingAddress`, `No_Transactions`, `Fraud`.  
  - Filtros:
    1. Clientes marcados como fraude.  
    2. Direcciones de facturaciÃ³n duplicadas.  
    3. Clientes con fraude y mÃ¡s de 2 transacciones.

---

## âœ… Conclusiones Generales

- **Counterfeit** â†’ Permite detectar fraude en transacciones y optimizar logÃ­stica.  
- **Olist** â†’ Centrado en datos de clientes, Ãºtil para segmentaciÃ³n y geografÃ­a.  
- **Customer_DF** â†’ Enfocado en fraude por contacto/dispositivo, muy Ãºtil en ciberseguridad.  

Este ecosistema de bases de datos brinda un **pipeline completo de BI**, cubriendo **transacciones, clientes y riesgo** desde mÃºltiples fuentes.

---

## ğŸš€ TecnologÃ­as utilizadas
- **PostgreSQL + Docker** â†’ Almacenamiento relacional.  
- **Python (pandas, SQLAlchemy)** â†’ Procesamiento de datos.  
- **Jupyter / DataSpell** â†’ ExploraciÃ³n y documentaciÃ³n.  
- **Kaggle + datasets acadÃ©micos** â†’ Fuentes de datos abiertas.
