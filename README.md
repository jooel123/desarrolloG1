# ğŸ›¡ï¸ Proyecto BI â€“ Counterfeit Product Detection

Este proyecto implementa un flujo de **Inteligencia de Negocios** usando PostgreSQL, Python (pandas, SQLAlchemy) y Jupyter Notebooks.  
Se trabaja con el dataset de [Counterfeit Product Detection](https://www.kaggle.com/datasets/aimlveera/counterfeit-product-detection-dataset), estructurÃ¡ndolo en **tres DataFrames principales** para anÃ¡lisis.

---

## ğŸ“Š 1. DataFrame de Transacciones (`df_transacciones`)

### DescripciÃ³n
Contiene cada operaciÃ³n registrada en el dataset. Es la fuente base para anÃ¡lisis financiero y de riesgo.

| Columna              | DescripciÃ³n                                |
|----------------------|--------------------------------------------|
| transaction_id       | Identificador Ãºnico de la transacciÃ³n      |
| transaction_date     | Fecha de la operaciÃ³n                      |
| customer_id          | Cliente asociado                           |
| quantity, unit_price | Cantidad y precio unitario                 |
| total_amount         | Monto total                                |
| payment_method       | Forma de pago                              |
| shipping_speed       | Velocidad de envÃ­o                         |
| discount_applied     | Indicador de descuento aplicado            |
| refund_requested     | Solicitud de reembolso                     |
| velocity_flag        | Bandera de velocidad (fraude)              |
| geolocation_mismatch | Bandera de geolocalizaciÃ³n                 |

### Filtros aplicados
1. **Transacciones de alto valor** â†’ top 10% de `total_amount`.  
2. **Transacciones con banderas de riesgo** â†’ `velocity_flag`, `geolocation_mismatch`, `refund_requested`.  
3. **Transacciones con descuentos altos** â†’ `discount_percentage >= 30%`.

---

## ğŸ‘¤ 2. DataFrame de Clientes (`df_clientes`)

### DescripciÃ³n
Agrupa mÃ©tricas a nivel de cliente para segmentaciÃ³n de usuarios.

| Columna                  | DescripciÃ³n                                 |
|--------------------------|---------------------------------------------|
| customer_id              | Identificador Ãºnico del cliente             |
| total_pedidos            | NÃºmero de compras realizadas                |
| monto_total              | Valor total acumulado                       |
| ticket_promedio          | Valor promedio de compra                    |
| tasa_reembolso           | ProporciÃ³n de pedidos con devoluciÃ³n        |
| flags_riesgo             | NÃºmero de alertas de fraude asociadas       |
| customer_location_mas_comun | UbicaciÃ³n mÃ¡s frecuente del cliente     |

### Filtros aplicados
1. **Clientes VIP** â†’ top 10% en `monto_total`.  
2. **Clientes riesgosos** â†’ `tasa_reembolso >= 30%` o `flags_riesgo > 0`.  
3. **Clientes frecuentes** â†’ `total_pedidos >= 5`.

---

## ğŸšš 3. DataFrame de LogÃ­stica (`df_logistica`)

### DescripciÃ³n
EvalÃºa desempeÃ±o logÃ­stico y cumplimiento de SLA (tiempo objetivo de entrega).

| Columna             | DescripciÃ³n                              |
|---------------------|------------------------------------------|
| shipping_speed      | Modalidad de envÃ­o                       |
| delivery_time_days  | Tiempo real de entrega (dÃ­as)            |
| shipping_cost       | Costo del envÃ­o                          |
| sla_dias            | SLA asignado segÃºn modalidad             |
| cumple_sla          | Indicador de cumplimiento del SLA        |

### Filtros aplicados
1. **EnvÃ­os fuera de SLA** â†’ `cumple_sla = FALSE`.  
2. **EnvÃ­os costosos** â†’ top 10% en `shipping_cost`.  
3. **EnvÃ­os lentos** â†’ `delivery_time_days >= 10`.

---

## âœ… Conclusiones

- **Transacciones** â†’ permiten identificar operaciones sospechosas (fraude, alto valor, devoluciones).  
- **Clientes** â†’ se segmentan en VIP, frecuentes y riesgosos.  
- **LogÃ­stica** â†’ se mide eficiencia, costos y cumplimiento de SLA.  

Este esquema de **3 DataFrames + filtros** habilita un pipeline de **Inteligencia de Negocios** Ãºtil para detecciÃ³n de fraude, anÃ¡lisis de clientes estratÃ©gicos y optimizaciÃ³n logÃ­stica.

---

## ğŸš€ TecnologÃ­as utilizadas
- **PostgreSQL + Docker** â†’ base de datos principal.  
- **Python (pandas, SQLAlchemy)** â†’ procesamiento y anÃ¡lisis de datos.  
- **Jupyter / DataSpell** â†’ entorno de notebooks.  
- **Kaggle Dataset** â†’ fuente de datos (CSV).

---
